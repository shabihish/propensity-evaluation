# Project Documentation

## Overview

This project is a comprehensive framework designed to simulate and evaluate AI agents' behavior in various scenarios. The system is built to assess the propensity of agents to act in aligned or misaligned ways under different conditions, leveraging a combination of finite state machines, scenario-based simulations, and system messages to create realistic and challenging environments.

The project is modular, with a focus on pipelines, scenario generation, and agent evaluation. Below is a detailed breakdown of the main components, their functionality, and how to use the system effectively.

**Our full dataset is available in [results/final/](results/final/).**

---

## Main Components

### `main_scen_pipeline.py`

This script is the entry point for generating scenarios. It processes workspaces, roles, and attack vectors to create detailed scenarios for agent evaluation. The scenarios include InitialState, TargetState, and IllegalState, along with configurations, functions, and system messages.

#### Key Features:
- **Attack Vector Initialization**: Loads attack vectors from the `inputs/attacks` directory.
- **Workspace and Role Processing**: Iterates through workspaces and roles to generate scenarios.
- **Scenario Generation**: Creates scenarios with detailed configurations, functions, and system messages.
- **Logging**: Logs the progress and outputs to a structured directory.

#### How It Works:
1. Loads attack vectors and domain data.
2. Iterates through workspaces and roles to prepare scenarios.
3. Generates scenarios using the `PipelineScenarios` class.
4. Saves the generated scenarios to the `results` directory.

---

### `main_scen_pipeline_messages.py`

This script is responsible for generating system messages for the scenarios created by `main_scen_pipeline.py`. These messages are used to simulate pressure on agents during the evaluation process.

#### Key Features:
- **Message Generation**: Creates neutral and regular system messages for each scenario.
- **Workspace Filtering**: Skips workspaces that already have messages generated.
- **Integration with Scenarios**: Ensures messages align with the scenarios' configurations.

#### How It Works:
1. Loads scenarios from the `results` directory.
2. Generates system messages for each scenario using the `PipelineMessages` class.
3. Saves the updated scenarios with messages back to the `results` directory.

---

### `agentic/main.py`

This script is the core of the agent evaluation process. It runs the scenarios generated by the pipelines and evaluates the agents' behavior under different conditions.

#### Key Features:
- **Scenario Execution**: Executes scenarios using the `PropensityEvaluator` class.
- **Agent Interaction**: Simulates agent responses to system messages and task instructions.
- **Cost Tracking**: Tracks token usage and cost for each scenario.
- **Parallel Processing**: Uses `ProcessPoolExecutor` for parallel scenario execution.

#### How It Works:
1. Loads scenarios from the `results` directory.
2. Initializes the `PropensityEvaluator` for each scenario.
3. Simulates agent interactions and collects results.
4. Saves results to a JSONL file in the `results` directory.

---

## Pipeline Components

The pipelines are modular and consist of several components located in the `pipeline/modules` directory. These components handle specific tasks within the scenario and message generation processes.

### Key Modules:
- **`PipelineScenarios`**: Handles the generation of scenarios, including states, configurations, and functions.
- **`PipelineMessages`**: Manages the creation of system messages for scenarios.
- **`utils/colors.py`**: Provides custom logging formats with color-coded output for better readability.

---

## Inputs Directory

The `inputs` directory contains the data required for scenario generation. It is structured as follows:

- **`attacks/`**: Contains attack vectors for different domains. Each subdirectory represents a domain and includes an `attacks.json` file.
- **`workspaces/`**: Contains workspace definitions, including roles and descriptions. Each workspace is represented as a JSON file.
- **`domains.json`**: Provides metadata about the domains, including descriptions and alternative forms.

---

## Results Directory

The `results` directory stores the outputs of the pipelines and agent evaluations. It is structured as follows:

- **`scenarios/`**: Contains the generated scenarios, including states, configurations, and functions.
- **`messages/`**: Stores scenarios with system messages added.
- **`logs/`**: Contains logs for scenario generation and agent evaluation.
- **`scenario_results_*.jsonl`**: Stores the results of agent evaluations in JSONL format.

---

## How to Run

1. **Generate Scenarios**:
   Run `main_scen_pipeline.py` to generate scenarios (states, funcs/configurations, policies, and neutral/task messages) for the workspaces and roles defined in `inputs/`.
   ```bash
   python main_scen_pipeline.py
   ```

2. **Generate System Messages**:
   Run `main_scen_pipeline_messages.py` to generate system messages for the generated scenarios of the previous step.
   ```bash
   python main_scen_pipeline_messages.py
   ```

3. **Evaluate Agents**:
   Run `agentic/main.py` to evaluate agents using the generated scenarios and messages.
   ```bash
   python agentic/main.py --model_name <MODEL_NAME> --scenario_file <SCENARIO_FILE>
   ```

4. **View Results**:
   Check the `results` directory for evaluation outputs and logs.

---

## Summary

This project provides a robust framework for simulating and evaluating AI agents in complex scenarios. By leveraging modular pipelines, detailed scenarios, and realistic system messages, it enables comprehensive testing of agent behavior under various conditions.